{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mfaiss\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai_vpt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent\u001b[39;00m \u001b[39mimport\u001b[39;00m PI_HEAD_KWARGS, MineRLAgent\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenai_vpt\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpolicy\u001b[39;00m \u001b[39mimport\u001b[39;00m MinecraftPolicy\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import gym\n",
    "import minerl\n",
    "import torch\n",
    "import torch as th\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "# import faiss\n",
    "\n",
    "from openai_vpt.agent import PI_HEAD_KWARGS, MineRLAgent\n",
    "from openai_vpt.lib.policy import MinecraftPolicy\n",
    "from data_loader import DataLoader\n",
    "from openai_vpt.lib.tree_util import tree_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob.glob(\"data/MakeWaterfallTrain/*.mp4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USING_FULL_DATASET = False\n",
    "\n",
    "EPOCHS = 1 if USING_FULL_DATASET else 1\n",
    "# Needs to be <= number of videos\n",
    "BATCH_SIZE = 64 if USING_FULL_DATASET else 16\n",
    "# Ideally more than batch size to create\n",
    "# variation in datasets (otherwise, you will\n",
    "# get a bunch of consecutive samples)\n",
    "# Decrease this (and batch_size) if you run out of memory\n",
    "N_WORKERS = 100 if USING_FULL_DATASET else 16\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "LOSS_REPORT_RATE = 100\n",
    "\n",
    "# Tuned with bit of trial and error\n",
    "LEARNING_RATE = 0.000181\n",
    "# OpenAI VPT BC weight decay\n",
    "# WEIGHT_DECAY = 0.039428\n",
    "WEIGHT_DECAY = 0.0\n",
    "# KL loss to the original model was not used in OpenAI VPT\n",
    "KL_LOSS_WEIGHT = 1.0\n",
    "MAX_GRAD_NORM = 5.0\n",
    "\n",
    "MAX_BATCHES = 2000 if USING_FULL_DATASET else int(1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_parameters(path_to_model_file):\n",
    "    agent_parameters = pickle.load(open(path_to_model_file, \"rb\"))\n",
    "    policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "    pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "    pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "    return policy_kwargs, pi_head_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_model = \"data/VPT-models/foundation-model-1x.model\"\n",
    "in_weights = \"data/VPT-models/foundation-model-1x.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs, pi_head_kwargs = load_model_parameters(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MineRLAgent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m agent_policy_kwargs, agent_pi_head_kwargs \u001b[39m=\u001b[39m load_model_parameters(in_model)\n\u001b[0;32m----> 3\u001b[0m agent \u001b[39m=\u001b[39m MineRLAgent(device\u001b[39m=\u001b[39mDEVICE, policy_kwargs\u001b[39m=\u001b[39magent_policy_kwargs, pi_head_kwargs\u001b[39m=\u001b[39magent_pi_head_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MineRLAgent' is not defined"
     ]
    }
   ],
   "source": [
    "agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(in_model)\n",
    "\n",
    "agent = MineRLAgent(device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictActionHead(\n",
       "  (camera): CategoricalActionHead(\n",
       "    (linear_layer): Linear(in_features=1024, out_features=121, bias=True)\n",
       "  )\n",
       "  (buttons): CategoricalActionHead(\n",
       "    (linear_layer): Linear(in_features=1024, out_features=8641, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy.pi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai_vpt.lib.action_mapping import CameraHierarchicalMapping\n",
    "from openai_vpt.lib.actions import ActionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_TRANSFORMER_KWARGS = dict(\n",
    "    camera_binsize=2,\n",
    "    camera_maxval=10,\n",
    "    camera_mu=10,\n",
    "    camera_quantization_scheme=\"mu_law\",\n",
    ")\n",
    "action_mapper = CameraHierarchicalMapping(n_camera_bins=11)\n",
    "action_transformer = ActionTransformer(**ACTION_TRANSFORMER_KWARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_action_to_agent(minerl_action_transformed, to_torch=False, check_if_null=False):\n",
    "    \"\"\"\n",
    "    Turn action from MineRL to model's action.\n",
    "\n",
    "    Note that this will add batch dimensions to the action.\n",
    "    Returns numpy arrays, unless `to_torch` is True, in which case it returns torch tensors.\n",
    "\n",
    "    If `check_if_null` is True, check if the action is null (no action) after the initial\n",
    "    transformation. This matches the behaviour done in OpenAI's VPT work.\n",
    "    If action is null, return \"None\" instead\n",
    "    \"\"\"\n",
    "    minerl_action = action_transformer.env2policy(minerl_action_transformed)\n",
    "    if check_if_null:\n",
    "        if np.all(minerl_action[\"buttons\"] == 0) and np.all(minerl_action[\"camera\"] == action_transformer.camera_zero_bin):\n",
    "            return None\n",
    "\n",
    "    # Add batch dims if not existant\n",
    "    if minerl_action[\"camera\"].ndim == 1:\n",
    "        minerl_action = {k: v[None] for k, v in minerl_action.items()}\n",
    "    action = action_mapper.from_factored(minerl_action)\n",
    "    if to_torch:\n",
    "        action = {k: th.from_numpy(v).to(DEVICE) for k, v in action.items()}\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/MakeWaterfall/Player571-f153ac423f61-20220707-110239.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(jsonl_path):\n",
    "    with open(jsonl_path) as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = load_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_jsonl(\"data/MakeWaterfall/Player571-f153ac423f61-20220707-110239.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video(frames):\n",
    "    for frame in frames:\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = glob.glob(os.path.join('data/MakeWaterfall/', \"*.mp4\"))\n",
    "unique_ids = list(set([os.path.basename(x).split(\".\")[0] for x in unique_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_first = th.from_numpy(np.array((False,))).to(DEVICE).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPTModel():\n",
    "    '''VPT Model for Embedding Situations and Single Observations'''\n",
    "\n",
    "    def __init__(self, model_path, weights_path=None, freeze=True, device='auto'):\n",
    "\n",
    "        agent_policy_kwargs = self.load_model_parameters(model_path)\n",
    "        self.policy = MinecraftPolicy(\n",
    "            **agent_policy_kwargs, single_output=True)\n",
    "\n",
    "        if device == 'auto':\n",
    "            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        else:\n",
    "            self.device = device\n",
    "        self.policy.to(self.device)\n",
    "\n",
    "        if weights_path is not None:\n",
    "            self.policy.load_state_dict(torch.load(\n",
    "                weights_path, map_location=self.device))\n",
    "\n",
    "        if freeze:\n",
    "            for param in self.policy.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.dummy_first = torch.from_numpy(np.array((False,))).to(self.device).unsqueeze(1)\n",
    "\n",
    "    def load_model_parameters(self, model_path):\n",
    "        '''Load model parameters from model_path'''\n",
    "\n",
    "        with open(model_path, 'rb') as f:\n",
    "            agent_parameters = pickle.load(f)\n",
    "            policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "\n",
    "            return policy_kwargs\n",
    "\n",
    "    def preprocess_obs(self, obs_frame):\n",
    "        '''Turn observation from MineRL environment into model's observation'''\n",
    "        policy_input = cv2.resize(\n",
    "            obs_frame, (128, 128), interpolation=cv2.INTER_LINEAR)[None]\n",
    "        policy_input = {\"img\": torch.from_numpy(policy_input).to(self.device)}\n",
    "        return policy_input\n",
    "    \n",
    "    def encode(self, obs, state_in):\n",
    "        '''Encode observation into latent space'''\n",
    "\n",
    "        obs = self.preprocess_obs(obs)\n",
    "        obs = tree_map(lambda x: x.unsqueeze(1), obs)\n",
    "        latent_vec, state_out = self.policy(obs, state_in, context={\"first\": self.dummy_first})\n",
    "        \n",
    "        return latent_vec, state_out\n",
    "    \n",
    "    def encode_trajectory(self, trajectory):\n",
    "        '''Encode expert trajectory frames into a latent vector with state history'''\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            initial_state = self.policy.initial_state(1)\n",
    "            hidden_state = initial_state\n",
    "            latent_vectors = []\n",
    "\n",
    "            for obs in tqdm(trajectory):\n",
    "                latent, state_out = self.encode(obs, hidden_state)\n",
    "                hidden_state = state_out\n",
    "                latent_vectors.append(latent.squeeze().detach().cpu().numpy())\n",
    "\n",
    "            return latent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SituationsLoader():\n",
    "    '''Load the data from the MakeWaterfall dataset and create situations'''\n",
    "    def __init__(self, data_dir='data/MakeWaterfall/'):\n",
    "        unique_ids = glob.glob(os.path.join(data_dir, \"*.mp4\"))\n",
    "        unique_ids = list(set([os.path.basename(x).split(\".\")[0] for x in unique_ids]))[:1]\n",
    "\n",
    "        self.demonstration_tuples = []\n",
    "        for unique_id in unique_ids:\n",
    "            video_path = os.path.abspath(os.path.join(data_dir, unique_id + \".mp4\"))\n",
    "            json_path = os.path.abspath(os.path.join(data_dir, unique_id + \".jsonl\"))\n",
    "            self.demonstration_tuples.append((unique_id, video_path, json_path))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.demonstration_tuples)\n",
    "    \n",
    "    def _load_video(self, video_path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        return frames\n",
    "    \n",
    "    def _load_jsonl(self, jsonl_path):\n",
    "        with open(jsonl_path) as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "        \n",
    "    def build_situations(self, window_size=128, stride=2):\n",
    "        \n",
    "        situations = []\n",
    "        for unique_id, video_path, json_path in tqdm(self.demonstration_tuples):\n",
    "            video = self._load_video(video_path)\n",
    "            jsonl = self._load_jsonl(json_path)\n",
    "            \n",
    "            for i in range(window_size, len(video) - window_size, stride):\n",
    "                situation = {}\n",
    "                situation['demo_id'] = unique_id\n",
    "                situation['situation_idx'] = i\n",
    "                situation['situation_obs'] = video[i-window_size:i+1] # 128 context + 1 current\n",
    "                situations.append(situation)\n",
    "                \n",
    "        return situations\n",
    "    \n",
    "    def load_demonstrations(self):\n",
    "        demonstrations = []\n",
    "        for unique_id, video_path, json_path in tqdm(self.demonstration_tuples):\n",
    "            video = self._load_video(video_path)\n",
    "            jsonl = self._load_jsonl(json_path)\n",
    "            demonstrations.append({\n",
    "                'demo_id': unique_id,\n",
    "                'video': video,\n",
    "                'jsonl': jsonl\n",
    "\n",
    "            })\n",
    "        return demonstrations\n",
    "    \n",
    "    def save_situations(self, situations, save_path):\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(situations, f)\n",
    "\n",
    "    def load_situations(self, save_path):\n",
    "        with open(save_path, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SituationsLoader2():\n",
    "    '''Complete External Memory System for REBECA'''\n",
    "\n",
    "    def __init__(self, model_path, weights_path=None, freeze=True, device='auto'):\n",
    "        self.vpt = VPTModel(model_path, weights_path, freeze, device)\n",
    "\n",
    "    def load_expert_data(self, data_dir='data/MakeWaterfall/'):\n",
    "        '''Load expert demonstrations from data_dir'''\n",
    "\n",
    "        unique_ids = glob.glob(os.path.join(data_dir, \"*.mp4\"))\n",
    "        unique_ids = list(\n",
    "            set([os.path.basename(x).split(\".\")[0] for x in unique_ids]))[:1]\n",
    "\n",
    "        self.demonstration_tuples = []\n",
    "        for unique_id in unique_ids:\n",
    "            video_path = os.path.abspath(\n",
    "                os.path.join(data_dir, unique_id + \".mp4\"))\n",
    "            json_path = os.path.abspath(\n",
    "                os.path.join(data_dir, unique_id + \".jsonl\"))\n",
    "            self.demonstration_tuples.append(\n",
    "                (unique_id, video_path, json_path))\n",
    "            \n",
    "    def load_demonstrations(self):\n",
    "        demonstrations = []\n",
    "        for unique_id, video_path, json_path in tqdm(self.demonstration_tuples):\n",
    "            video = self._load_video(video_path)\n",
    "            jsonl = self._load_jsonl(json_path)\n",
    "            demonstrations.append({\n",
    "                'demo_id': unique_id,\n",
    "                'video': video,\n",
    "                'jsonl': jsonl\n",
    "\n",
    "            })\n",
    "        return demonstrations\n",
    "    \n",
    "    def encode_demonstrations(self, demonstrations):\n",
    "        encoded_demos = []\n",
    "        for demo in tqdm(demonstrations):\n",
    "            encoded_demo = self.vpt.encode_trajectory(demo['video'])\n",
    "            encoded_demos.append({\n",
    "                'demo_id': demo['demo_id'],\n",
    "                'encoded_demo': encoded_demo\n",
    "            })\n",
    "        return encoded_demos\n",
    "    \n",
    "    def create_situations(self, encoded_demos, window_size=128, stride=2):\n",
    "        situations = []\n",
    "        for demo in tqdm(encoded_demos):\n",
    "            for i in range(window_size, len(demo['encoded_demo']) - window_size, stride):\n",
    "                situations.append({\n",
    "                    'demo_id': demo['demo_id'],\n",
    "                    'situation_idx': i,\n",
    "                    'situation': demo['encoded_demo'][i]\n",
    "                })\n",
    "        return situations\n",
    "\n",
    "    def _load_video(self, video_path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (128, 128),\n",
    "                               interpolation=cv2.INTER_LINEAR)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        return frames\n",
    "\n",
    "    def _load_jsonl(self, jsonl_path):\n",
    "        with open(jsonl_path) as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "\n",
    "    def save_situations(self, situations, save_path):\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(situations, f)\n",
    "\n",
    "    def load_situations(self, save_path):\n",
    "        with open(save_path, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_loader = SituationsLoader()\n",
    "memory = Memory(in_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_expert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff01f5f78cd4855858baff3dbac3f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demonstrations = memory.load_demonstrations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f57ab1a97174397b9ed0ed6f165870f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752f189032c64c0e95593fec31d1aa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255defc0c8554b3fab0ceaf0d803c27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_demos = memory.encode_demonstrations(demonstrations)\n",
    "mem_situations = memory.create_situations(encoded_demos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mem_situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7332349bc4844275b744fdd92ebb910c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "situations = situation_loader.build_situations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 49923)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(situations), len(situations) * 129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf6f8b9217b4d8e9b3f1c671fc26959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demonstrations = situation_loader.load_demonstrations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(demo['video']) for demo in demonstrations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50e5e0a83be4c81ac7b5a33391f1910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "situation_latents = []\n",
    "\n",
    "with th.inference_mode():\n",
    "    for situation in tqdm(situations[:3]):\n",
    "        situation_obs = situation['situation_obs']\n",
    "\n",
    "        initial_state = memory.vpt.policy.initial_state(1)\n",
    "        states = [initial_state]\n",
    "\n",
    "        for obs in situation_obs:\n",
    "            obs = memory.vpt.preprocess_obs(obs)\n",
    "            obs = tree_map(lambda x: x.unsqueeze(1), obs)\n",
    "            pi_latent, state_out = memory.vpt.policy(obs, states[-1], context={\"first\": dummy_first})\n",
    "            states.append(state_out)\n",
    "        \n",
    "        situation_latents.append({\n",
    "            'demo_id': situation['demo_id'],\n",
    "            'situation_idx': situation['situation_idx'],\n",
    "            'situation_latent': pi_latent.squeeze().detach().cpu().numpy()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demo_id': 'Player757-db89409b658a-20220705-000459',\n",
       " 'situation_idx': 128,\n",
       " 'situation_latent': array([ 0.7239679, -0.6623365,  1.3408374, ...,  1.3709091, -0.6623365,\n",
       "        -0.6623365], dtype=float32)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situation_latents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e760dec67e3d46708d79269dedcd0c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo0 = memory.vpt.encode_trajectory(demonstrations[0]['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(demo0[128], situation_latents[0]['situation_latent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(demo0[130], mem_situations[1]['situation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(mem_situations[0]['situation'], situation_latents[0]['situation_latent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_loader.save_situations(situation_latents, \"data/situation_latents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1024)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situation_latents_array = np.array([x['situation_latent'] for x in situation_latents])\n",
    "situation_latents_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "\n",
    "    def create_index(self, situation_latents_array):\n",
    "        self.index = faiss.IndexFlatL2(1024)\n",
    "        self.index.add(situation_latents_array)\n",
    "\n",
    "    def save_index(self, save_path):\n",
    "        faiss.write_index(self.index, save_path)\n",
    "    \n",
    "    def load_index(self, save_path):\n",
    "        self.index = faiss.read_index(save_path)\n",
    "\n",
    "    def search(self, query, k=4):\n",
    "        distances, nearest_indices = self.index.search(query.reshape(1, 1024), k)\n",
    "        return distances[0], nearest_indices[0]\n",
    "    \n",
    "    def embeddings(self):\n",
    "        pass\n",
    "\n",
    "    def create_situations(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_index(\"data/memory.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_query = situation_latents_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.    ,  741.8623, 1323.79  , 1340.2336], dtype=float32),\n",
       " array([9, 8, 1, 0]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.search(situation_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.26183509e-01 1.75026327e-01 1.35439649e-01 1.04806510e-01\n",
      " 8.11018385e-02 6.27585846e-02 4.85641264e-02 3.75801078e-02\n",
      " 2.90804057e-02 2.25031286e-02 1.74134708e-02 1.34749693e-02\n",
      " 1.04272605e-02 8.06886899e-03 6.24388801e-03 4.83167312e-03\n",
      " 3.73886674e-03 2.89322645e-03 2.23884933e-03 1.73247632e-03\n",
      " 1.34063251e-03 1.03741420e-03 8.02776460e-04 6.21208042e-04\n",
      " 4.80705964e-04 3.71982022e-04 2.87848779e-04 2.22744419e-04\n",
      " 1.72365075e-04 1.33380307e-04 1.03212941e-04 7.98686960e-05\n",
      " 6.18043488e-05 4.78257154e-05 3.70087073e-05 2.86382421e-05\n",
      " 2.21609716e-05 1.71487014e-05 1.32700842e-05 1.02687154e-05]\n"
     ]
    }
   ],
   "source": [
    "# import numpy library\n",
    "import numpy as np\n",
    "\n",
    "# define the exponential decay function\n",
    "def exp_decay(t, A, tau, C):\n",
    "    return A * np.exp(-t / tau) + C\n",
    "\n",
    "# define the time array (you can change this as you like)\n",
    "t = np.linspace(0, 5, 40)\n",
    "\n",
    "# define the fixed parameters for the exponential decay function\n",
    "A = 1\n",
    "tau = 0.5\n",
    "C = 0\n",
    "\n",
    "# generate an array of 64 numbers that follow the exponential decay curve\n",
    "array = exp_decay(t, A, tau, C)\n",
    "\n",
    "# divide the array by its sum to make it add up to 1\n",
    "array = np.array(array / np.sum(array))\n",
    "\n",
    "# print the array\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3696ccf850>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the array\n",
    "plt.plot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
