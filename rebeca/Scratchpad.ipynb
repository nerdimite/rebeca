{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "import gym\n",
    "import minerl\n",
    "import torch\n",
    "import torch as th\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import faiss\n",
    "\n",
    "from openai_vpt.agent import PI_HEAD_KWARGS, MineRLAgent\n",
    "from openai_vpt.lib.policy import MinecraftPolicy\n",
    "from data_loader import DataLoader\n",
    "from openai_vpt.lib.tree_util import tree_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USING_FULL_DATASET = False\n",
    "\n",
    "EPOCHS = 1 if USING_FULL_DATASET else 1\n",
    "# Needs to be <= number of videos\n",
    "BATCH_SIZE = 64 if USING_FULL_DATASET else 16\n",
    "# Ideally more than batch size to create\n",
    "# variation in datasets (otherwise, you will\n",
    "# get a bunch of consecutive samples)\n",
    "# Decrease this (and batch_size) if you run out of memory\n",
    "N_WORKERS = 100 if USING_FULL_DATASET else 16\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "LOSS_REPORT_RATE = 100\n",
    "\n",
    "# Tuned with bit of trial and error\n",
    "LEARNING_RATE = 0.000181\n",
    "# OpenAI VPT BC weight decay\n",
    "# WEIGHT_DECAY = 0.039428\n",
    "WEIGHT_DECAY = 0.0\n",
    "# KL loss to the original model was not used in OpenAI VPT\n",
    "KL_LOSS_WEIGHT = 1.0\n",
    "MAX_GRAD_NORM = 5.0\n",
    "\n",
    "MAX_BATCHES = 2000 if USING_FULL_DATASET else int(1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_parameters(path_to_model_file):\n",
    "    agent_parameters = pickle.load(open(path_to_model_file, \"rb\"))\n",
    "    policy_kwargs = agent_parameters[\"model\"][\"args\"][\"net\"][\"args\"]\n",
    "    pi_head_kwargs = agent_parameters[\"model\"][\"args\"][\"pi_head_opts\"]\n",
    "    pi_head_kwargs[\"temperature\"] = float(pi_head_kwargs[\"temperature\"])\n",
    "    return policy_kwargs, pi_head_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_model = \"data/VPT-models/foundation-model-1x.model\"\n",
    "in_weights = \"data/VPT-models/foundation-model-1x.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(in_model)\n",
    "policy = MinecraftPolicy(**agent_policy_kwargs, single_output=True)\n",
    "policy.to(DEVICE)\n",
    "# agent = MineRLAgent(device=DEVICE, policy_kwargs=agent_policy_kwargs, pi_head_kwargs=agent_pi_head_kwargs)\n",
    "# agent.load_weights(in_weights)\n",
    "# policy = agent.policy\n",
    "\n",
    "for param in policy.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"data/MakeWaterfall/Player571-f153ac423f61-20220707-110239.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_frames(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(jsonl_path):\n",
    "    with open(jsonl_path) as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = load_frames(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load_jsonl(\"data/MakeWaterfall/Player571-f153ac423f61-20220707-110239.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(obs_frame):\n",
    "    \"\"\"\n",
    "    Turn observation from MineRL environment into model's observation\n",
    "\n",
    "    Returns torch tensors.\n",
    "    \"\"\"\n",
    "    agent_input = cv2.resize(obs_frame, (128, 128), interpolation=cv2.INTER_LINEAR)[None]\n",
    "    agent_input = {\"img\": th.from_numpy(agent_input).to(DEVICE)}\n",
    "    return agent_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_video(frames):\n",
    "    for frame in frames:\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = glob.glob(os.path.join('data/MakeWaterfall/', \"*.mp4\"))\n",
    "unique_ids = list(set([os.path.basename(x).split(\".\")[0] for x in unique_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SituationsLoader():\n",
    "    '''Load the data from the MakeWaterfall dataset and create situations'''\n",
    "    def __init__(self, data_dir='data/MakeWaterfall/'):\n",
    "        unique_ids = glob.glob(os.path.join(data_dir, \"*.mp4\"))\n",
    "        unique_ids = list(set([os.path.basename(x).split(\".\")[0] for x in unique_ids]))\n",
    "\n",
    "        self.demonstration_tuples = []\n",
    "        for unique_id in unique_ids:\n",
    "            video_path = os.path.abspath(os.path.join(data_dir, unique_id + \".mp4\"))\n",
    "            json_path = os.path.abspath(os.path.join(data_dir, unique_id + \".jsonl\"))\n",
    "            self.demonstration_tuples.append((unique_id, video_path, json_path))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.demonstration_tuples)\n",
    "    \n",
    "    def _load_video(self, video_path):\n",
    "        frames = []\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "            frames.append(frame)\n",
    "        cap.release()\n",
    "        return frames\n",
    "    \n",
    "    def _load_jsonl(self, jsonl_path):\n",
    "        with open(jsonl_path) as f:\n",
    "            return [json.loads(line) for line in f]\n",
    "        \n",
    "    def build_situations(self, window_size=128, stride=2):\n",
    "        \n",
    "        situations = []\n",
    "        for unique_id, video_path, json_path in tqdm(self.demonstration_tuples):\n",
    "            video = self._load_video(video_path)\n",
    "            jsonl = self._load_jsonl(json_path)\n",
    "            \n",
    "            for i in range(window_size, len(video) - window_size, stride):\n",
    "                situation = {}\n",
    "                situation['demo_id'] = unique_id\n",
    "                situation['situation_idx'] = i\n",
    "                situation['situation_obs'] = video[i-window_size:i+1] # 128 context + 1 current\n",
    "                situations.append(situation)\n",
    "                \n",
    "        return situations\n",
    "    \n",
    "    def save_situations(self, situations, save_path):\n",
    "        with open(save_path, 'wb') as f:\n",
    "            pickle.dump(situations, f)\n",
    "\n",
    "    def load_situations(self, save_path):\n",
    "        with open(save_path, 'rb') as f:\n",
    "            return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_loader = SituationsLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c54395f8fd42b6aa7568e7ee57e8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "situations = situation_loader.build_situations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12200"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = \"data/situations.pkl\"\n",
    "# situation_loader.save_situations(situations, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl_loaded_data = situation_loader.load_situations(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f981de6e1c584c24a5d82c1bc5571c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy_first = th.from_numpy(np.array((False,))).to(DEVICE).unsqueeze(1)\n",
    "\n",
    "situation_latents = []\n",
    "\n",
    "with th.inference_mode():\n",
    "    for situation in tqdm(situations[:10]):\n",
    "        situation_obs = situation['situation_obs']\n",
    "\n",
    "        initial_state = policy.initial_state(1)\n",
    "        states = [initial_state]\n",
    "\n",
    "        for obs in situation_obs:\n",
    "            obs = preprocess(obs)\n",
    "            obs = tree_map(lambda x: x.unsqueeze(1), obs)\n",
    "            pi_latent, state_out = policy(obs, states[-1], context={\"first\": dummy_first})\n",
    "            states.append(state_out)\n",
    "        \n",
    "        situation_latents.append({\n",
    "            'demo_id': situation['demo_id'],\n",
    "            'situation_idx': situation['situation_idx'],\n",
    "            'situation_latent': pi_latent.squeeze().detach().cpu().numpy()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_loader.save_situations(situation_latents, \"data/situation_latents.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1024)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situation_latents_array = np.array([x['situation_latent'] for x in situation_latents])\n",
    "situation_latents_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "\n",
    "    def create_index(self, situation_latents_array):\n",
    "        self.index = faiss.IndexFlatL2(1024)\n",
    "        self.index.add(situation_latents_array)\n",
    "\n",
    "    def save_index(self, save_path):\n",
    "        faiss.write_index(self.index, save_path)\n",
    "    \n",
    "    def load_index(self, save_path):\n",
    "        self.index = faiss.read_index(save_path)\n",
    "\n",
    "    def search(self, query, k=4):\n",
    "        distances, nearest_indices = self.index.search(query.reshape(1, 1024), k)\n",
    "        return distances[0], nearest_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_index(\"data/memory.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "situation_query = situation_latents_array[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0.    ,  741.8623, 1323.79  , 1340.2336], dtype=float32),\n",
       " array([9, 8, 1, 0]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.search(situation_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
