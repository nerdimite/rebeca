{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from model import VPTEncoder, Controller\n",
    "from memory import SituationLoader, Memory\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from openai_vpt.lib.action_mapping import CameraHierarchicalMapping\n",
    "from openai_vpt.lib.actions import ActionTransformer\n",
    "from action_utils import ActionProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_model = \"data/VPT-models/foundation-model-1x.model\"\n",
    "in_weights = \"data/VPT-models/foundation-model-1x-net.weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(in_weights, map_location=\"cpu\")\n",
    "# # keep weights only for the net part\n",
    "# state = {k: v for k, v in state.items() if k.startswith(\"net.\")}\n",
    "# # remove the \"net.\" prefix\n",
    "# state = {k[4:]: v for k, v in state.items()}\n",
    "# torch.save(state, \"data/VPT-models/foundation-model-1x-net.weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vpt = VPTEncoder(in_model, in_weights)\n",
    "vpt.eval()\n",
    "expert_dataloader = SituationLoader(vpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrations = expert_dataloader.load_demonstrations(num_demos=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_demos = expert_dataloader.encode_demonstrations(demonstrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "situations = expert_dataloader.create_situations(encoded_demos, stride=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "#   VPT Encoder (Frozen)\n",
    "# \tMemory\n",
    "# Rebeca Policy\n",
    "# \tRetriever\n",
    "# \tVPT Backbone (Trainable)\n",
    "# \tController\n",
    "# Forward\n",
    "# \tRetrieve Situations\n",
    "# \tobs = VPT Backbone (obs)\n",
    "# \tpreprocess retrieved situations\n",
    "# \tkey, cam = Controller(obs, situations, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever():\n",
    "    def __init__(self, encoder_model, encoder_weights, memory_path):\n",
    "        self.vpt = VPTEncoder(encoder_model, encoder_weights)\n",
    "        self.vpt.eval()\n",
    "        self.memory = Memory()\n",
    "        self.memory.load_index(memory_path)\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def encode_query(self, query_obs):\n",
    "        query_obs_vec, state_out = self.vpt(query_obs, self.hidden_state)\n",
    "        self.hidden_state = state_out\n",
    "        query_obs_vec = query_obs_vec.squeeze().cpu().numpy()\n",
    "        return query_obs_vec\n",
    "\n",
    "    def retrieve(self, query_obs, k=2):\n",
    "        query_obs_vec = self.encode_query(query_obs)\n",
    "        results = self.memory.search(query_obs_vec, k=k)\n",
    "\n",
    "        if results[0]['distance'] == 0: # to prevent returning the same situation and overfitting\n",
    "            print(\"Same situation found\")\n",
    "            return results[1]\n",
    "        else:\n",
    "            return results[0]\n",
    "\n",
    "    def reset(self):\n",
    "        self.hidden_state = self.vpt.policy.initial_state(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Retriever(in_model, in_weights, \"data/memory.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_video(video_path):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (128, 128), interpolation=cv2.INTER_LINEAR)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demonstration(demo_id, root_dir=\"data/MakeWaterfall\"):\n",
    "    video_path = f\"{root_dir}/{demo_id}.mp4\"\n",
    "    frames = _load_video(video_path)\n",
    "    return frames\n",
    "\n",
    "def load_situation(situation_id, demo_frames):\n",
    "    situation = demo_frames[situation_id]\n",
    "    return situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obs in demonstrations[0]['video'][150:200]:\n",
    "    result = retriever.retrieve(obs)\n",
    "    print(result['distance'])\n",
    "    plt.imshow(obs[..., ::-1])\n",
    "    plt.show()\n",
    "    res_demo = load_demonstration(result['demo_id'])\n",
    "    res_situation = load_situation(result['sit_frame_idx'], res_demo)\n",
    "    plt.imshow(res_situation[..., ::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REBECA(nn.Module):\n",
    "    def __init__(self, encoder_model, encoder_weights, memory_path, controller_path, controller_weights):\n",
    "        super().__init__()\n",
    "        self.retriever = Retriever(encoder_model, encoder_weights, memory_path)\n",
    "        self.vpt = VPTEncoder(encoder_model, encoder_weights)\n",
    "        self.controller = Controller(controller_path, controller_weights)\n",
    "\n",
    "    def forward(self, obs, actions):\n",
    "        result = self.retriever.retrieve(obs)\n",
    "        res_demo = load_demonstration(result['demo_id'])\n",
    "        res_situation = load_situation(result['sit_frame_idx'], res_demo)\n",
    "        action = self.controller(obs, res_situation, actions)\n",
    "        return action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minerl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
